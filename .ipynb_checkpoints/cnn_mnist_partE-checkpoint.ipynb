{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  \n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "  # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 64 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_convnet_model_102', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F5198A7240>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/mnist_convnet_model_102\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.09475737 0.09493138 0.10061827 0.09648113 0.10660056 0.09159371\n",
      "  0.10345118 0.10357773 0.10121433 0.10677427]\n",
      " [0.10519344 0.10270426 0.08963366 0.08464338 0.1206909  0.0938093\n",
      "  0.09534783 0.10220467 0.1023271  0.10344554]\n",
      " [0.09785815 0.1048729  0.09543516 0.09906473 0.10909547 0.08864158\n",
      "  0.10218731 0.10563156 0.10089525 0.09631795]\n",
      " [0.09441606 0.09352485 0.09280925 0.09577103 0.11474538 0.10117983\n",
      "  0.09309403 0.09736922 0.10698471 0.11010557]\n",
      " [0.09652693 0.10233942 0.09276522 0.09059619 0.11003088 0.08788812\n",
      "  0.11277823 0.11696168 0.099832   0.09028127]\n",
      " [0.09488078 0.09987449 0.0993506  0.08565644 0.12304904 0.09145503\n",
      "  0.10679446 0.09607359 0.09899173 0.10387386]\n",
      " [0.0902945  0.10324397 0.09597927 0.0897219  0.11848594 0.10045337\n",
      "  0.09557056 0.11163952 0.09583916 0.09877188]\n",
      " [0.09993248 0.10084591 0.09863508 0.09197976 0.11093846 0.09787775\n",
      "  0.10418946 0.09698901 0.1017013  0.09691074]\n",
      " [0.10832786 0.08242989 0.10724232 0.08029231 0.09397868 0.10234497\n",
      "  0.10014634 0.09972275 0.11284178 0.11267302]\n",
      " [0.10979434 0.10155226 0.10849278 0.0898824  0.09313048 0.07916323\n",
      "  0.10385585 0.10323899 0.10130811 0.10958165]\n",
      " [0.10369342 0.1060949  0.09509066 0.0941914  0.12022271 0.08561823\n",
      "  0.09747389 0.09892356 0.10217642 0.09651479]\n",
      " [0.11269554 0.08136795 0.10064284 0.09468241 0.1135383  0.08369753\n",
      "  0.09262709 0.09358273 0.10489847 0.12226717]\n",
      " [0.11232831 0.09775485 0.10051465 0.10117994 0.09473696 0.07894122\n",
      "  0.09997488 0.10765873 0.10179006 0.10512043]\n",
      " [0.11872619 0.10306137 0.09285602 0.09841658 0.0958597  0.0919144\n",
      "  0.08383892 0.09749807 0.1132686  0.10456024]\n",
      " [0.10107028 0.09259335 0.08968481 0.09155215 0.12370208 0.09312938\n",
      "  0.10483877 0.1093211  0.0909422  0.10316578]\n",
      " [0.10294547 0.0971776  0.08727799 0.08318323 0.11086252 0.09418125\n",
      "  0.10359021 0.10183678 0.11145545 0.10748948]\n",
      " [0.11078662 0.08978129 0.08974789 0.08501045 0.12067228 0.0989804\n",
      "  0.09624353 0.10816543 0.09742512 0.10318693]\n",
      " [0.10190951 0.10148219 0.09447117 0.09167612 0.10618439 0.09571839\n",
      "  0.09330209 0.09598781 0.11730125 0.10196707]\n",
      " [0.10378095 0.09535731 0.09613276 0.112317   0.10117669 0.08358159\n",
      "  0.10501069 0.09349909 0.11066102 0.09848287]\n",
      " [0.09451961 0.09717776 0.09289154 0.07759059 0.10266425 0.09992816\n",
      "  0.11031334 0.11440648 0.11738194 0.09312633]\n",
      " [0.09462664 0.10256443 0.1001524  0.09803458 0.1262451  0.09483492\n",
      "  0.08864908 0.09628335 0.09460492 0.10400461]\n",
      " [0.09302064 0.09120417 0.07919187 0.09648547 0.11515283 0.08876175\n",
      "  0.10398643 0.12661059 0.10401084 0.10157546]\n",
      " [0.10187948 0.09345037 0.10152794 0.09928044 0.10224859 0.09195221\n",
      "  0.1034468  0.09599447 0.10882883 0.10139086]\n",
      " [0.08514905 0.10021969 0.09180149 0.0891288  0.10924362 0.08575375\n",
      "  0.10549807 0.10562079 0.12010306 0.10748167]\n",
      " [0.09590184 0.09689822 0.09114029 0.09406366 0.11151893 0.09620994\n",
      "  0.09999046 0.11067178 0.09722722 0.10637773]\n",
      " [0.11022858 0.09607329 0.09884162 0.09560778 0.09519965 0.08013593\n",
      "  0.09724164 0.1047315  0.11414874 0.1077913 ]\n",
      " [0.09439383 0.09563484 0.09415942 0.08252059 0.11988907 0.08356889\n",
      "  0.10809839 0.1265971  0.09936158 0.09577627]\n",
      " [0.0911798  0.10348547 0.09935554 0.09566168 0.11852263 0.08808167\n",
      "  0.11047327 0.11668461 0.09137612 0.08517917]\n",
      " [0.09917345 0.08784889 0.09337474 0.09760676 0.11340718 0.08375477\n",
      "  0.09805547 0.1209921  0.10518678 0.10059975]\n",
      " [0.10756921 0.08514731 0.0915912  0.08686813 0.10831968 0.08906638\n",
      "  0.12664975 0.10773828 0.103892   0.09315806]\n",
      " [0.10706534 0.10282129 0.10515756 0.08322726 0.10321042 0.09917017\n",
      "  0.0960433  0.10247209 0.09865461 0.102178  ]\n",
      " [0.1040443  0.09728196 0.10278089 0.09792062 0.09585945 0.09108698\n",
      "  0.09784018 0.0993123  0.1042197  0.10965362]\n",
      " [0.09898102 0.10777339 0.08886944 0.08927789 0.12434209 0.08572103\n",
      "  0.10014948 0.09967922 0.10525219 0.0999542 ]\n",
      " [0.10459083 0.09385917 0.08929583 0.08561123 0.13694751 0.08849774\n",
      "  0.09306295 0.10533017 0.10479705 0.09800757]\n",
      " [0.10159925 0.0953332  0.09998202 0.08802589 0.09855888 0.0909889\n",
      "  0.10887199 0.10213252 0.11222744 0.10227984]\n",
      " [0.1045986  0.0958124  0.0958818  0.10380325 0.12423573 0.079876\n",
      "  0.0989859  0.10577293 0.10126232 0.08977112]\n",
      " [0.09995511 0.09857395 0.08820359 0.08782426 0.11299006 0.09007633\n",
      "  0.10139906 0.10338255 0.10776502 0.10983007]\n",
      " [0.10121109 0.09356159 0.08813792 0.08776134 0.12823328 0.09160902\n",
      "  0.09893805 0.107999   0.10631025 0.09623845]\n",
      " [0.09681146 0.10943551 0.09304682 0.09615205 0.11850465 0.07691056\n",
      "  0.09606642 0.12170084 0.10701939 0.08435225]\n",
      " [0.10249104 0.09651703 0.09265419 0.09115928 0.11622132 0.0948864\n",
      "  0.09601773 0.10636445 0.10091329 0.10277523]\n",
      " [0.10868234 0.09708904 0.09561855 0.08669027 0.11687081 0.08749222\n",
      "  0.10951319 0.09457982 0.10072029 0.10274345]\n",
      " [0.09310116 0.1041274  0.09948736 0.09736741 0.11536732 0.09163877\n",
      "  0.09556226 0.10705747 0.09916092 0.09713004]\n",
      " [0.0859679  0.09072013 0.09328185 0.09693553 0.12086438 0.08885657\n",
      "  0.12489795 0.10236873 0.10844009 0.08766683]\n",
      " [0.11991389 0.10862195 0.08847567 0.09537439 0.09349234 0.08521824\n",
      "  0.11230913 0.09261477 0.11385369 0.09012591]\n",
      " [0.09402364 0.09920438 0.09759434 0.10165597 0.10730086 0.09456503\n",
      "  0.09430828 0.0998058  0.10432515 0.10721658]\n",
      " [0.10074368 0.09608363 0.10050143 0.09273021 0.11675216 0.09165742\n",
      "  0.09278335 0.09897374 0.11317099 0.09660329]\n",
      " [0.09503751 0.0873529  0.09821497 0.09016804 0.11210398 0.08810992\n",
      "  0.11271553 0.11923175 0.11119108 0.08587434]\n",
      " [0.09758289 0.10593782 0.09374852 0.10149123 0.10505497 0.09802943\n",
      "  0.09518922 0.09755537 0.09490661 0.11050399]\n",
      " [0.10468555 0.09175991 0.10545748 0.09109994 0.10954119 0.08821834\n",
      "  0.1063247  0.09949079 0.09830505 0.10511703]\n",
      " [0.10028954 0.10763559 0.09378909 0.11005058 0.10534716 0.08200988\n",
      "  0.09270443 0.11666913 0.09804978 0.09345473]]\n",
      "INFO:tensorflow:loss = 2.301944, step = 1\n",
      "INFO:tensorflow:probabilities = [[0.00005837 0.000077   0.00211694 0.9386495  0.00000342 0.0584633\n",
      "  0.00023284 0.00001371 0.0003822  0.00000274]\n",
      " [0.0000699  0.9968501  0.00054479 0.00006222 0.00025977 0.00017156\n",
      "  0.00095803 0.00029197 0.00069471 0.00009701]\n",
      " [0.0013928  0.00039652 0.10728018 0.00269268 0.00002245 0.00373899\n",
      "  0.0000367  0.00007632 0.8843115  0.00005189]\n",
      " [0.00032135 0.9880328  0.00074999 0.00003035 0.00010045 0.000934\n",
      "  0.00240394 0.00014    0.00727085 0.00001611]\n",
      " [0.00002862 0.00000098 0.03520102 0.86490846 0.00000002 0.09869132\n",
      "  0.00007404 0.0000004  0.00109513 0.00000001]\n",
      " [0.0001472  0.00005618 0.98141104 0.00468804 0.00001064 0.00045531\n",
      "  0.00067103 0.00000054 0.01255911 0.00000083]\n",
      " [0.00002649 0.0000015  0.99668485 0.00009387 0.0000471  0.00042997\n",
      "  0.00001141 0.00001226 0.00128909 0.00140341]\n",
      " [0.0088798  0.00001828 0.00007565 0.00058795 0.05972223 0.04553963\n",
      "  0.00035471 0.07658716 0.00385176 0.80438286]\n",
      " [0.00007588 0.9955621  0.00145735 0.00013518 0.0001922  0.00008873\n",
      "  0.00063453 0.00016132 0.00127819 0.0004145 ]\n",
      " [0.9324774  0.         0.00001957 0.00005941 0.00000003 0.06313391\n",
      "  0.0000008  0.00421351 0.00005438 0.00004118]\n",
      " [0.00000657 0.00000239 0.00001255 0.00000129 0.9985129  0.00050691\n",
      "  0.00005857 0.0000628  0.00001083 0.00082504]\n",
      " [0.9978067  0.         0.0005688  0.00000073 0.00000077 0.00099575\n",
      "  0.00001439 0.00002551 0.00046891 0.00011864]\n",
      " [0.9888278  0.         0.00000307 0.00000401 0.00000003 0.01054926\n",
      "  0.00000017 0.00003112 0.00058134 0.00000333]\n",
      " [0.0000087  0.00000457 0.00001059 0.00003122 0.00000254 0.00008017\n",
      "  0.00000097 0.00000272 0.9998362  0.00002233]\n",
      " [0.00000006 0.00000016 0.99994314 0.00003936 0.00000008 0.00000043\n",
      "  0.00000064 0.00000001 0.00001607 0.        ]\n",
      " [0.00644164 0.00001659 0.9905234  0.00181157 0.00000439 0.00057008\n",
      "  0.00010892 0.00002368 0.00040382 0.00009594]\n",
      " [0.00000029 0.00000032 0.00043124 0.9935707  0.00000066 0.005668\n",
      "  0.00000003 0.00001959 0.00028867 0.00002063]\n",
      " [0.00258879 0.00246277 0.00229412 0.00508465 0.00931693 0.9426915\n",
      "  0.00515524 0.00409364 0.02170928 0.00460299]\n",
      " [0.00059167 0.97520113 0.00192344 0.00007411 0.00630189 0.00774003\n",
      "  0.00328311 0.00028367 0.00439788 0.0002032 ]\n",
      " [0.99810445 0.00000001 0.0000623  0.00000084 0.00000001 0.00157894\n",
      "  0.00001311 0.00000041 0.00023849 0.00000159]\n",
      " [0.00431819 0.01184903 0.03189758 0.00539628 0.00050807 0.00277093\n",
      "  0.00191262 0.00239935 0.9157607  0.02318722]\n",
      " [0.00000089 0.         0.00000111 0.00000002 0.00000006 0.00000022\n",
      "  0.         0.9998085  0.00000232 0.00018699]\n",
      " [0.00080481 0.17750762 0.08108933 0.00113784 0.05907281 0.08183111\n",
      "  0.00025857 0.01879053 0.5784153  0.00109212]\n",
      " [0.969075   0.         0.00025725 0.00000664 0.00000009 0.03018855\n",
      "  0.00005106 0.00000104 0.00041552 0.00000469]\n",
      " [0.00000109 0.         0.00000461 0.         0.00000003 0.00002024\n",
      "  0.99997306 0.         0.0000009  0.00000001]\n",
      " [0.0009749  0.00000941 0.01404126 0.00008441 0.00006384 0.00317772\n",
      "  0.00003013 0.00092416 0.9521933  0.02850089]\n",
      " [0.00011031 0.00003715 0.00012726 0.98144203 0.00000806 0.01665879\n",
      "  0.00000193 0.00001631 0.00118879 0.00040932]\n",
      " [0.00032488 0.00013623 0.0004453  0.00063879 0.09167923 0.00752687\n",
      "  0.00170783 0.01928102 0.01430338 0.8639565 ]\n",
      " [0.00086257 0.9593448  0.01344176 0.00021612 0.00401305 0.00277085\n",
      "  0.00102491 0.00019042 0.01783832 0.00029716]\n",
      " [0.00006649 0.00001671 0.00050399 0.9956311  0.00000027 0.00315317\n",
      "  0.00000019 0.00029424 0.0000365  0.00029737]\n",
      " [0.00000104 0.0000011  0.00003118 0.00000007 0.00000742 0.00000257\n",
      "  0.         0.99835324 0.00021495 0.00138841]\n",
      " [0.00031177 0.01317052 0.00016795 0.00623896 0.14405221 0.06213441\n",
      "  0.00048565 0.06159218 0.02952676 0.68231964]\n",
      " [0.0003726  0.00000126 0.00005284 0.874206   0.00000763 0.12209992\n",
      "  0.00000008 0.00013332 0.0004582  0.00266803]\n",
      " [0.00242558 0.01241198 0.0090097  0.0133332  0.3435983  0.20704442\n",
      "  0.00292205 0.04209781 0.07907558 0.28808126]\n",
      " [0.9974317  0.00000035 0.00076456 0.00002748 0.00000105 0.00088255\n",
      "  0.00028213 0.00002003 0.0003903  0.00019987]\n",
      " [0.05923035 0.00000047 0.00107223 0.00554017 0.0000002  0.09511757\n",
      "  0.00000033 0.7817207  0.05620182 0.00111622]\n",
      " [0.00000019 0.00000008 0.99994636 0.00000335 0.00000004 0.00000013\n",
      "  0.0000011  0.         0.00004886 0.00000001]\n",
      " [0.00051353 0.0000001  0.00001586 0.0025865  0.00000016 0.99438286\n",
      "  0.00005384 0.00000034 0.00244369 0.00000311]\n",
      " [0.0000078  0.00000032 0.00000175 0.00000056 0.00000037 0.00044652\n",
      "  0.9995401  0.         0.00000246 0.00000006]\n",
      " [0.00002    0.0000108  0.00013624 0.98891556 0.00000002 0.01063975\n",
      "  0.00000003 0.00000393 0.00027218 0.00000151]\n",
      " [0.         0.         0.99988496 0.00002233 0.00000006 0.00000032\n",
      "  0.00000014 0.         0.00009218 0.00000002]\n",
      " [0.00000208 0.         0.00000548 0.         0.00000009 0.000008\n",
      "  0.9999831  0.         0.00000137 0.00000001]\n",
      " [0.00000223 0.00000082 0.00002093 0.00000275 0.00017795 0.00000954\n",
      "  0.00000015 0.00063274 0.00231424 0.9968387 ]\n",
      " [0.99722147 0.         0.00030148 0.00000087 0.00000023 0.00127705\n",
      "  0.00115437 0.00000376 0.00003976 0.00000112]\n",
      " [0.00119875 0.00000364 0.00032323 0.00003306 0.00003497 0.9947843\n",
      "  0.00261248 0.00000636 0.00100023 0.00000288]\n",
      " [0.00002807 0.00004439 0.00001371 0.00022869 0.00343686 0.00189383\n",
      "  0.00000249 0.03436344 0.0038701  0.9561184 ]\n",
      " [0.00011484 0.99181926 0.00315475 0.00014643 0.00044829 0.00028003\n",
      "  0.00192033 0.00041239 0.0012832  0.00042061]\n",
      " [0.00003657 0.00014783 0.00445031 0.0000524  0.94525766 0.00308232\n",
      "  0.00092948 0.00297239 0.00500155 0.03806942]\n",
      " [0.00218038 0.00004243 0.00031938 0.42254645 0.00003369 0.57302463\n",
      "  0.00006234 0.00009155 0.00157518 0.00012401]\n",
      " [0.8318196  0.00002044 0.08878604 0.00448596 0.00047385 0.049407\n",
      "  0.00234066 0.00124718 0.01824262 0.00317666]] (7.706 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.55178\n",
      "INFO:tensorflow:probabilities = [[0.0003019  0.00000131 0.00014716 0.00006319 0.00036695 0.00058922\n",
      "  0.00237259 0.00149969 0.9934314  0.00122663]\n",
      " [0.00005446 0.00034382 0.00000813 0.00212659 0.07777037 0.00059129\n",
      "  0.00000228 0.06724703 0.00867311 0.843183  ]\n",
      " [0.00001382 0.         0.00000062 0.00000005 0.0000001  0.00001446\n",
      "  0.00000004 0.00000181 0.9999386  0.00003057]\n",
      " [0.0000004  0.00001424 0.0000003  0.9854174  0.00012271 0.01366596\n",
      "  0.00000579 0.00008174 0.00068242 0.00000903]\n",
      " [0.00000352 0.00034319 0.00000168 0.00025897 0.98721004 0.00025196\n",
      "  0.00000652 0.00772342 0.00052918 0.00367156]\n",
      " [0.00004463 0.00042047 0.00018427 0.00327324 0.00011462 0.00194086\n",
      "  0.00004979 0.0000767  0.9938539  0.00004142]\n",
      " [0.9998355  0.         0.00000786 0.00000047 0.00000242 0.00002642\n",
      "  0.00005678 0.00000527 0.00006322 0.00000218]\n",
      " [0.00002923 0.99674916 0.00004058 0.00039504 0.00035475 0.00007098\n",
      "  0.00040345 0.00101408 0.00082822 0.0001145 ]\n",
      " [0.0096605  0.00013756 0.807975   0.00112189 0.00019389 0.00042682\n",
      "  0.0000966  0.00215875 0.17547664 0.00275236]\n",
      " [0.00009827 0.00008017 0.00648574 0.00205685 0.20249137 0.17348617\n",
      "  0.00076813 0.00051065 0.58560646 0.02841621]\n",
      " [0.00000006 0.00000011 0.0000013  0.999752   0.00000008 0.00002453\n",
      "  0.         0.00000747 0.00020894 0.00000547]\n",
      " [0.00003089 0.00020784 0.00024682 0.00120108 0.00001066 0.00023362\n",
      "  0.00000094 0.00012914 0.99787986 0.00005927]\n",
      " [0.999788   0.         0.0000005  0.00001357 0.         0.00011121\n",
      "  0.00000003 0.00001425 0.00006972 0.00000274]\n",
      " [0.0000087  0.95850897 0.00028334 0.00004286 0.01158689 0.00001448\n",
      "  0.0000782  0.02883963 0.00058448 0.00005248]\n",
      " [0.00001495 0.00014723 0.00510322 0.00003391 0.0034869  0.01124458\n",
      "  0.6546455  0.00000016 0.32531333 0.00001025]\n",
      " [0.00000006 0.00000006 0.00000399 0.00006283 0.00025942 0.00000148\n",
      "  0.         0.01236162 0.00013318 0.9871774 ]\n",
      " [0.00000542 0.00003152 0.00000304 0.00008825 0.9724099  0.00031483\n",
      "  0.00001004 0.01909521 0.00005613 0.00798562]\n",
      " [0.00003021 0.9968098  0.00023475 0.00011824 0.00011556 0.00000362\n",
      "  0.00029108 0.00115141 0.00117846 0.00006685]\n",
      " [0.9890745  0.00000084 0.00003635 0.000178   0.00000436 0.00022977\n",
      "  0.00993694 0.00001823 0.00051668 0.00000423]\n",
      " [0.99281645 0.00000127 0.00002978 0.00005099 0.00000101 0.00588357\n",
      "  0.00018008 0.00002303 0.00101251 0.00000109]\n",
      " [0.00019001 0.00001368 0.00009732 0.00011708 0.00031213 0.99509335\n",
      "  0.00103537 0.00032306 0.00280451 0.00001348]\n",
      " [0.00000775 0.9970681  0.00009218 0.00010622 0.00032888 0.0000107\n",
      "  0.00078927 0.00138111 0.00014601 0.00006977]\n",
      " [0.99978334 0.         0.00000005 0.00000121 0.         0.0001202\n",
      "  0.00000001 0.00001346 0.00007919 0.00000263]\n",
      " [0.00000505 0.98270506 0.00123405 0.00005244 0.01446284 0.00003951\n",
      "  0.00034125 0.00047951 0.00068038 0.00000005]\n",
      " [0.00000402 0.00000741 0.00000228 0.00001176 0.01682802 0.00006078\n",
      "  0.00000004 0.02544711 0.00054139 0.95709723]\n",
      " [0.00000401 0.00015592 0.00008823 0.85019064 0.0002368  0.10608993\n",
      "  0.00000192 0.00001436 0.04315475 0.00006335]\n",
      " [0.00016774 0.9898948  0.00007917 0.0001013  0.00114933 0.00026541\n",
      "  0.00351996 0.00077048 0.0039968  0.000055  ]\n",
      " [0.00026234 0.00003785 0.00001501 0.00207762 0.09639975 0.00265997\n",
      "  0.00000596 0.14481229 0.00120266 0.7525265 ]\n",
      " [0.00650822 0.00000437 0.1212988  0.03068489 0.01130169 0.03170133\n",
      "  0.00047743 0.00075615 0.79479957 0.00246751]\n",
      " [0.00000116 0.00004593 0.00057436 0.9988476  0.00000512 0.00034489\n",
      "  0.00000013 0.00000554 0.00015205 0.00002315]\n",
      " [0.01052387 0.0000159  0.00010154 0.02755485 0.00003087 0.0911595\n",
      "  0.00065218 0.00003855 0.8695838  0.00033885]\n",
      " [0.9992205  0.00000035 0.00003417 0.00000746 0.00000318 0.0002313\n",
      "  0.00004869 0.00035464 0.00007612 0.00002346]\n",
      " [0.03921222 0.02010567 0.7048298  0.0147288  0.00006042 0.00014592\n",
      "  0.19927362 0.00015845 0.02147722 0.00000795]\n",
      " [0.00014645 0.00000507 0.00000098 0.02322133 0.00000709 0.95364743\n",
      "  0.0000808  0.00000457 0.02282215 0.00006411]\n",
      " [0.00000079 0.00001647 0.00000534 0.00010389 0.00000197 0.00002915\n",
      "  0.00000001 0.9985637  0.00001536 0.0012634 ]\n",
      " [0.00001557 0.00056978 0.00001162 0.00011497 0.93393314 0.00034608\n",
      "  0.00012648 0.03431508 0.0111024  0.01946489]\n",
      " [0.         0.         0.         0.00008796 0.00000006 0.99923575\n",
      "  0.00000346 0.         0.00067274 0.00000001]\n",
      " [0.00071366 0.01179901 0.00010912 0.00002497 0.00092419 0.12907845\n",
      "  0.14864925 0.00000121 0.7086862  0.00001396]\n",
      " [0.00000064 0.00000012 0.00000047 0.00000028 0.00000874 0.00006097\n",
      "  0.9999107  0.         0.00001795 0.        ]\n",
      " [0.0168684  0.00162849 0.00218833 0.09422414 0.03055654 0.53960675\n",
      "  0.00398537 0.00298131 0.3070964  0.00086424]\n",
      " [0.00000004 0.00000129 0.00000488 0.99942136 0.00000013 0.00056385\n",
      "  0.         0.00000005 0.00000614 0.0000023 ]\n",
      " [0.0000154  0.00003478 0.00000925 0.00001042 0.00000559 0.00232949\n",
      "  0.00000047 0.00000548 0.99757415 0.00001503]\n",
      " [0.         0.0000001  0.         0.00000002 0.9860926  0.00000493\n",
      "  0.         0.01357647 0.00004712 0.0002787 ]\n",
      " [0.99965656 0.         0.00000027 0.00000047 0.00000001 0.00029738\n",
      "  0.0000057  0.         0.00003968 0.00000002]\n",
      " [0.00052871 0.00004734 0.00038841 0.00033937 0.99132264 0.00092825\n",
      "  0.00073978 0.00538037 0.00005108 0.00027405]\n",
      " [0.00035888 0.0034689  0.00128297 0.00227766 0.97005504 0.00160839\n",
      "  0.00132872 0.00229032 0.00078799 0.01654113]\n",
      " [0.00000096 0.00000012 0.00000007 0.00000043 0.00000033 0.00004038\n",
      "  0.9999567  0.         0.00000099 0.        ]\n",
      " [0.0001359  0.00000031 0.00001404 0.0000049  0.00008032 0.11333933\n",
      "  0.00288289 0.         0.8835383  0.00000396]\n",
      " [0.00002825 0.0065148  0.00001285 0.00121732 0.00284976 0.00112888\n",
      "  0.00000227 0.79027325 0.02926552 0.16870718]\n",
      " [0.00448703 0.00343902 0.01897803 0.00231742 0.84891915 0.00194162\n",
      "  0.04604738 0.02204389 0.04293007 0.00889645]] (7.557 sec)\n",
      "INFO:tensorflow:loss = 0.2854277, step = 101 (15.260 sec)\n",
      "INFO:tensorflow:probabilities = [[0.00001251 0.00045656 0.0000508  0.00002539 0.00010554 0.02417901\n",
      "  0.9745554  0.00000037 0.00061317 0.00000125]\n",
      " [0.00000059 0.00000005 0.00000032 0.00000011 0.00000003 0.00009138\n",
      "  0.99990714 0.         0.00000037 0.        ]\n",
      " [0.00001649 0.0000037  0.00000224 0.00040044 0.00100758 0.00003095\n",
      "  0.00000004 0.01360582 0.0000219  0.98491085]\n",
      " [0.00030758 0.00001761 0.00009705 0.000006   0.00000046 0.01979556\n",
      "  0.00019126 0.00001484 0.97954893 0.00002075]\n",
      " [0.00007455 0.00000011 0.00480366 0.98487455 0.00000015 0.00362467\n",
      "  0.00000022 0.0006075  0.00009853 0.00591615]\n",
      " [0.00000084 0.00000513 0.99834955 0.00148125 0.00000013 0.00000004\n",
      "  0.         0.00015055 0.00001238 0.00000021]\n",
      " [0.0207759  0.00010632 0.06403103 0.03291516 0.57152957 0.00265572\n",
      "  0.00172311 0.16614057 0.00869869 0.13142397]\n",
      " [0.00027659 0.00029432 0.08271454 0.04490304 0.00005834 0.02306208\n",
      "  0.00068658 0.00193772 0.8455012  0.00056563]\n",
      " [0.00000095 0.00000095 0.00000031 0.00037293 0.00131355 0.00004462\n",
      "  0.00000001 0.0023462  0.00007186 0.99584866]\n",
      " [0.9999865  0.         0.00000115 0.00000091 0.         0.00000115\n",
      "  0.00000025 0.00000021 0.00000223 0.00000734]\n",
      " [0.00000068 0.9999833  0.00000813 0.00000293 0.0000009  0.00000001\n",
      "  0.00000027 0.00000079 0.00000289 0.00000001]\n",
      " [0.00000015 0.99940884 0.00001195 0.00001631 0.00029919 0.00002533\n",
      "  0.00001865 0.00000139 0.00021029 0.00000786]\n",
      " [0.00001457 0.         0.9997793  0.00020543 0.         0.00000001\n",
      "  0.         0.00000046 0.00000013 0.0000001 ]\n",
      " [0.00001248 0.0000053  0.00001191 0.00000258 0.00017773 0.00477187\n",
      "  0.99489486 0.00000026 0.00012243 0.00000073]\n",
      " [0.00000014 0.99997973 0.00000154 0.00000165 0.00001199 0.00000007\n",
      "  0.0000002  0.0000037  0.00000073 0.0000001 ]\n",
      " [0.00097325 0.00707617 0.00104762 0.00104192 0.00022887 0.00024061\n",
      "  0.00011368 0.00066987 0.9840771  0.00453091]\n",
      " [0.00000186 0.         0.00000722 0.         0.00000002 0.00004562\n",
      "  0.9999368  0.         0.00000841 0.00000001]\n",
      " [0.00000658 0.00590309 0.00011471 0.00205057 0.96670735 0.00117192\n",
      "  0.00004797 0.01057629 0.00936994 0.00405155]\n",
      " [0.00000042 0.00112573 0.8827852  0.11598478 0.00000001 0.00000028\n",
      "  0.00000001 0.00009731 0.00000611 0.00000009]\n",
      " [0.00039778 0.00000175 0.00002746 0.00063755 0.6415726  0.0009661\n",
      "  0.00188073 0.00792662 0.00176448 0.34482482]\n",
      " [0.00002035 0.9989889  0.00017156 0.00010022 0.00052356 0.00002707\n",
      "  0.00004459 0.00002154 0.00004474 0.00005739]\n",
      " [0.00000006 0.         0.         0.00000015 0.         0.999998\n",
      "  0.00000012 0.         0.00000169 0.00000004]\n",
      " [0.00000083 0.00000002 0.00000953 0.99969494 0.         0.00029148\n",
      "  0.         0.         0.00000308 0.00000015]\n",
      " [0.00001209 0.00000001 0.00000111 0.00000137 0.00000078 0.98646855\n",
      "  0.01339486 0.00000013 0.00012024 0.00000078]\n",
      " [0.         0.00000001 0.00065244 0.99934167 0.         0.\n",
      "  0.         0.00000584 0.00000001 0.00000003]\n",
      " [0.0113107  0.00001895 0.00049099 0.9729329  0.00000277 0.0141804\n",
      "  0.00001983 0.00097305 0.00001035 0.00006004]\n",
      " [0.0000574  0.99870944 0.00006833 0.00006235 0.00023162 0.00002401\n",
      "  0.00057144 0.00007681 0.00018079 0.00001769]\n",
      " [0.         0.         0.0000002  0.9998178  0.         0.00018183\n",
      "  0.         0.00000001 0.00000001 0.00000008]\n",
      " [0.0000261  0.00000223 0.00000172 0.00003245 0.0000006  0.99886286\n",
      "  0.00083192 0.00000183 0.00023811 0.00000213]\n",
      " [0.00000546 0.9996866  0.00003192 0.00012142 0.00001276 0.00000055\n",
      "  0.00001199 0.00009449 0.00002875 0.00000599]\n",
      " [0.00000026 0.         0.         0.00000374 0.         0.9999882\n",
      "  0.00000017 0.00000002 0.00000141 0.00000624]\n",
      " [0.01059676 0.00000002 0.00156959 0.00097761 0.00000336 0.19159517\n",
      "  0.00007231 0.00006293 0.77245224 0.02267006]\n",
      " [0.00000253 0.00000027 0.00000736 0.00273409 0.00000833 0.98945475\n",
      "  0.00001289 0.000047   0.00593475 0.00179813]\n",
      " [0.00000002 0.00006173 0.00003731 0.00045067 0.00000046 0.\n",
      "  0.         0.999408   0.00002185 0.00001997]\n",
      " [0.00007507 0.0000024  0.00015184 0.00392736 0.00004931 0.00112688\n",
      "  0.00000323 0.00072537 0.99053556 0.00340296]\n",
      " [0.00000017 0.99997056 0.00000324 0.00000191 0.00001133 0.00000002\n",
      "  0.00000043 0.00000562 0.00000671 0.00000007]\n",
      " [0.01295314 0.00000118 0.0000208  0.00006901 0.00000051 0.79061383\n",
      "  0.18062879 0.00000051 0.01550744 0.0002048 ]\n",
      " [0.00000241 0.00000013 0.00005396 0.00007511 0.00000174 0.00001595\n",
      "  0.00000026 0.0000095  0.9986646  0.00117635]\n",
      " [0.00003525 0.00953531 0.82552445 0.16178969 0.00011831 0.00000186\n",
      "  0.0000168  0.00036296 0.00179123 0.00082414]\n",
      " [0.00000107 0.00000023 0.9999715  0.00001259 0.00000003 0.00000016\n",
      "  0.         0.00000005 0.00001305 0.00000139]\n",
      " [0.00007845 0.00000211 0.000204   0.00018061 0.0000094  0.00004569\n",
      "  0.00000079 0.00038684 0.99871385 0.00037828]\n",
      " [0.00000005 0.00000336 0.0000691  0.99970204 0.00000003 0.00000929\n",
      "  0.         0.00003064 0.0000223  0.00016323]\n",
      " [0.99997747 0.         0.00000389 0.00000008 0.00000001 0.00000136\n",
      "  0.00001148 0.00000151 0.00000163 0.00000253]\n",
      " [0.9999993  0.         0.00000002 0.         0.         0.00000073\n",
      "  0.00000002 0.         0.         0.        ]\n",
      " [0.0001694  0.00000012 0.998689   0.00087068 0.00000062 0.00000165\n",
      "  0.0000006  0.0000216  0.00023775 0.0000087 ]\n",
      " [0.00004014 0.00000027 0.00000836 0.00031298 0.00002821 0.994383\n",
      "  0.00315509 0.00000259 0.00158063 0.00048869]\n",
      " [0.00002899 0.00000018 0.00000955 0.00000174 0.00000439 0.00203005\n",
      "  0.99791855 0.00000025 0.00000581 0.00000047]\n",
      " [0.00002623 0.00288867 0.00005951 0.0000987  0.9925148  0.00079931\n",
      "  0.00147952 0.00123327 0.00079677 0.00010319]\n",
      " [0.00087248 0.00601177 0.00168504 0.0032363  0.00002794 0.00073845\n",
      "  0.00012583 0.00005094 0.98694175 0.00030949]\n",
      " [0.00000112 0.00000142 0.00001362 0.00116522 0.00028195 0.0000116\n",
      "  0.00000001 0.993693   0.00000385 0.0048283 ]] (7.402 sec)\n"
     ]
    }
   ],
   "source": [
    "def main(unused_argv):\n",
    "  # Load training and eval data\n",
    "  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "  train_data = mnist.train.images  # Returns np.array\n",
    "  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "  eval_data = mnist.test.images  # Returns np.array\n",
    "  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "  # Create the Estimator\n",
    "  mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model_102\")\n",
    "\n",
    "  # Set up logging for predictions\n",
    "  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "  logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "  # Train the model\n",
    "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      batch_size=50,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "  mnist_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=3000,\n",
    "      hooks=[logging_hook])\n",
    "\n",
    "  # Evaluate the model and print results\n",
    "  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": eval_data},\n",
    "      y=eval_labels,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "  print(eval_results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
