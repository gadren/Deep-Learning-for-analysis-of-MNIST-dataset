{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Module Import</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Input and Output</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(\"float\", shape = [None,28,28,1])\n",
    "y_ = tf.placeholder(\"float\", shape = [None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Network Architecture</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = tf.Variable(tf.zeros([5,5,1,32]))\n",
    "b_conv1 = tf.Variable(tf.constant(.1, shape=[32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "<tf.Variable 'Variable:0' shape=(5, 5, 1, 32) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(W_conv1)\n",
    "h_conv1 = tf.nn.conv2d(input=x, filter=W_conv1, strides=[1,1,1,1], padding=\"SAME\") + b_conv1\n",
    "h_conv1 = tf.nn.relu(h_conv1)\n",
    "h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(input=x, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second Conv and Pool Layers\n",
    "W_conv2 = tf.Variable(tf.zeros([5, 5, 32, 64]))\n",
    "b_conv2 = tf.Variable(tf.constant(.1, shape = [64]))\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#First Fully Connected Layer\n",
    "W_fc1 = tf.Variable(tf.zeros([7 * 7 * 64, 1024]))\n",
    "b_fc1 = tf.Variable(tf.constant(.1, shape = [1024]))\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "#Dropout Layer\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#Second Fully Connected Layer\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([1024, 10], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(.1, shape = [10]))\n",
    "\n",
    "#Final Layer\n",
    "y = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Loss Function</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-cc391be9b397>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crossEntropyLoss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainStep = tf.train.AdamOptimizer().minimize(crossEntropyLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Cross Enropy Loss is illegal; using Cross_Enropy_Loss instead.\n"
     ]
    }
   ],
   "source": [
    "tf.summary.scalar('Cross Enropy Loss', crossEntropyLoss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n",
      "Tensor(\"Reshape_1:0\", shape=(1, 28, 28, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = mnist.train.next_batch(1)\n",
    "print(b[0].shape) #b[0] contains the image\n",
    "image = tf.reshape(b[0], [-1,28,28,1])\n",
    "print(image)\n",
    "my_img = image.eval() #here is your image Tensor\n",
    "my_i = my_img.squeeze()\n",
    "plt.imshow(my_i, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 training accuracy 0.05999999865889549\n",
      "step 100 training accuracy 0.1599999964237213\n",
      "step 200 training accuracy 0.07999999821186066\n",
      "step 300 training accuracy 0.05999999865889549\n",
      "step 400 training accuracy 0.05999999865889549\n",
      "step 500 training accuracy 0.07999999821186066\n",
      "step 600 training accuracy 0.10000000149011612\n",
      "step 700 training accuracy 0.11999999731779099\n",
      "step 800 training accuracy 0.07999999821186066\n",
      "step 900 training accuracy 0.07999999821186066\n"
     ]
    }
   ],
   "source": [
    "batchSize = 50\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(batchSize)\n",
    "    trainingInputs = batch[0].reshape([batchSize,28,28,1])\n",
    "    trainingLabels = batch[1]\n",
    "    if i%10 == 0:\n",
    "        summary = sess.run(merged, {x: trainingInputs, y_: trainingLabels, keep_prob: 1.0})\n",
    "        writer.add_summary(summary, i)\n",
    "    if i%100 == 0:\n",
    "        trainAccuracy = accuracy.eval(session=sess, feed_dict={x:trainingInputs, y_: trainingLabels, keep_prob: 1.0})\n",
    "        print(\"step {}\".format(i), \"training accuracy {}\".format(trainAccuracy))\n",
    "    trainStep.run(session=sess, feed_dict={x: trainingInputs, y_: trainingLabels, keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 0.09740000218153\n"
     ]
    }
   ],
   "source": [
    "testInputs = mnist.test.images.reshape([-1, 28, 28, 1])\n",
    "testLabels = mnist.test.labels\n",
    "acc = accuracy.eval(feed_dict = {x: testInputs, y_: testLabels, keep_prob: 1.0})\n",
    "print(\"testing accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
